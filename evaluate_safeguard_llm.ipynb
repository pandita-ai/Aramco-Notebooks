{"cells":[{"cell_type":"markdown","id":"OLtR8UD-w4cE","metadata":{"id":"OLtR8UD-w4cE"},"source":["Authored by: Aryan Mistry"]},{"cell_type":"markdown","id":"bb15edab","metadata":{"id":"bb15edab"},"source":["# Evaluating and Safeguarding LLM Applications\n","\n","Language models can produce fluent and impressive outputs, but it's crucial to evaluate how well they perform and to guard against undesirable behaviour. In this notebook we'll cover both **evaluation metrics** (how to measure quality) and **safety checks** (how to detect unfaithful or inappropriate content). We'll start with simple automatic metrics like BLEU, move on to heuristics for faithfulness, and end with structured output validation and basic guardrails. [12][13][14][15]"]},{"cell_type":"markdown","id":"b3ce75c9","metadata":{"id":"b3ce75c9"},"source":["## 1. Evaluation Metrics\n","\n","To quantify how good a model's output is we can measure it against a reference. Common metrics include:\n","\n","- **Perplexity:** Roughly speaking, perplexity measures how *surprised* a model is by the correct answer. Lower perplexity means the model assigns higher probability to the target sequence. It's often used when you have a trained model and want to see how well it fits your data.\n","- **BLEU:** Stands for Bilingual Evaluation Understudy. BLEU counts how many n‑grams (contiguous word sequences) the candidate shares with the reference. It works well for translation and summarisation tasks.\n","- **ROUGE:** Recall-Oriented Understudy for Gisting Evaluation. ROUGE focuses on recall (how much of the reference text appears in the candidate). It's popular for summarisation.\n","\n","No single metric is perfect, and automatic scores should be complemented with human judgments, especially for open‑ended outputs. [12][13]"]},{"cell_type":"markdown","id":"9208ea75","metadata":{"id":"9208ea75"},"source":["### 2. Unigram BLEU\n","\n","BLEU measures n-gram overlap between a candidate sentence (the model output)\n","and a reference sentence (ground truth). We'll start with the simplest case:\n","a **unigram BLEU** score that counts single-word overlaps. The precision of\n","matching unigrams is computed and normalised by the total number of words in\n","the candidate. In a full BLEU implementation you would include penalties for\n","short candidates and geometric means across multiple n-gram orders.\n","\n","Run the cell below to implement and test unigram BLEU. [12]\n"]},{"cell_type":"code","execution_count":null,"id":"877c1af5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1759724604599,"user":{"displayName":"Aryan Mistry","userId":"05905357547208756410"},"user_tz":420},"id":"877c1af5","outputId":"cf5a080c-f54f-4862-a5c1-6d2b69f42636"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unigram BLEU: 0.75\n","Unigram BLEU: 0.8333333333333334\n"]}],"source":["\n","from collections import Counter\n","\n","def unigram_bleu(candidate: str, reference: str) -> float:\n","    \"\"\"Compute unigram BLEU precision.\n","\n","    Counts overlapping single words between the candidate and reference, ignoring case.\n","    \"\"\"\n","    cand_tokens = candidate.lower().split()\n","    ref_tokens = reference.lower().split()\n","    ref_counts = Counter(ref_tokens)\n","    match_count = 0\n","    for token in cand_tokens:\n","        if ref_counts.get(token, 0) > 0:\n","            match_count += 1\n","            ref_counts[token] -= 1\n","    return match_count / max(len(cand_tokens), 1)\n","\n","candidate = \"humans landed on the moon with apollo 11\"\n","reference = \"A small step for man, a giant leap for mankind. The Apollo 11 mission landed humans on the moon.\"\n","print(f\"Unigram BLEU: {unigram_bleu(candidate, reference):.2f}\")\n","\n","\n","# Example usage:\n","if __name__ == '__main__':\n","    cand = 'the cat sat on the mat'\n","    ref = 'the cat is sitting on the mat'\n","    print('Unigram BLEU:', unigram_bleu(cand, ref))"]},{"cell_type":"markdown","id":"2ebe8a76","metadata":{"id":"2ebe8a76"},"source":["### 3. Bigram BLEU\n","\n","To capture short phrases rather than individual words, we can extend BLEU to\n","**bigrams** (two-word sequences). The procedure is similar: count matching\n","bigrams between candidate and reference. We'll implement bigram BLEU below. [12]\n"]},{"cell_type":"code","execution_count":null,"id":"53f55849","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1759724604617,"user":{"displayName":"Aryan Mistry","userId":"05905357547208756410"},"user_tz":420},"id":"53f55849","outputId":"0938c603-5eb6-4a75-cd3e-877e9d93682f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Bigram BLEU: 0.38\n","Bigram BLEU: 0.6\n"]}],"source":["\n","from collections import Counter\n","\n","def ngrams(tokens, n):\n","    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n","\n","def bigram_bleu(candidate: str, reference: str) -> float:\n","    \"\"\"Compute bigram BLEU precision.\n","\n","    This version counts overlapping two‑word sequences between the candidate and reference.\n","    \"\"\"\n","    cand_tokens = candidate.lower().split()\n","    ref_tokens = reference.lower().split()\n","    cand_bigrams = ngrams(cand_tokens, 2)\n","    ref_bigrams = ngrams(ref_tokens, 2)\n","    ref_counts = Counter(ref_bigrams)\n","    match_count = 0\n","    for bg in cand_bigrams:\n","        if ref_counts.get(bg, 0) > 0:\n","            match_count += 1\n","            ref_counts[bg] -= 1\n","    return match_count / max(len(cand_bigrams), 1)\n","\n","candidate_big = \"Neil Armstrong walked on the moon with Buzz Aldrin\"\n","reference_big = \"Buzz Aldrin and Neil Armstrong explored the moon during the Apollo missions.\"\n","print(f\"Bigram BLEU: {bigram_bleu(candidate_big, reference_big):.2f}\")\n","\n","\n","# Example usage:\n","if __name__ == '__main__':\n","    cand = 'the cat sat on the mat'\n","    ref = 'the cat is sitting on the mat'\n","    print('Bigram BLEU:', bigram_bleu(cand, ref))"]},{"cell_type":"markdown","id":"a3be133b","metadata":{"id":"a3be133b"},"source":["#### Exercises (Metrics)\n","\n","1. **Implement trigram BLEU.** Write a function `trigram_bleu(candidate, reference)` that computes the precision over three-word sequences. Test it on your own examples.\n","2. **Multiple references.** Modify your BLEU functions to accept a list of reference sentences and compute the maximum match count across references. How does this change the scores?\n","3. **Comparing metrics.** For a set of candidate sentences and references, compute unigram and bigram BLEU scores. Identify cases where the two metrics disagree and think about why.\n"]},{"cell_type":"markdown","id":"9078d188","metadata":{"id":"9078d188"},"source":["## 4. Faithfulness Heuristics\n","\n","Automatic metrics often fail to detect hallucinations—statements that sound\n","plausible but aren't supported by the source. A simple way to check\n","faithfulness is to verify whether important words in the answer also appear\n","in the context. We'll implement a basic heuristic below.\n","\n","First we define a list of common stop words (articles, conjunctions, etc.) and\n","then extract the remaining keywords from a text. Our `is_faithful` function\n","checks whether the answer's keywords are all contained in the context's\n","keywords. This is a very naive check; high-quality assessments often require\n","fact-checking pipelines or human evaluation. [14]\n"]},{"cell_type":"code","execution_count":null,"id":"07841552","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1759724604649,"user":{"displayName":"Aryan Mistry","userId":"05905357547208756410"},"user_tz":420},"id":"07841552","outputId":"9c0c939a-effe-44ee-a001-07fd3f42eb41"},"outputs":[{"name":"stdout","output_type":"stream","text":["Answer 1 faithful? True\n","Answer 2 faithful? False\n"]}],"source":["\n","import string\n","\n","STOP_WORDS = {\n","    'the','a','an','in','on','for','of','and','to','with','is','are','was','were',\n","    'this','that','these','those','as','by','at','from'\n","}\n","\n","def extract_keywords(text: str) -> set:\n","    \"\"\"Extract keywords from a text by removing stop words and punctuation.\n","\n","    Useful for naive faithfulness checks.\n","    \"\"\"\n","    translator = str.maketrans('', '', string.punctuation)\n","    words = text.translate(translator).lower().split()\n","    return {w for w in words if w not in STOP_WORDS}\n","\n","def is_faithful(answer: str, context: str) -> bool:\n","    ans_kw = extract_keywords(answer)\n","    ctx_kw = extract_keywords(context)\n","    return ans_kw <= ctx_kw\n","\n","context_text = \"Humans landed on the moon during the Apollo missions.\"\n","answer_true = \"Humans landed on the moon during the Apollo missions.\"\n","answer_false = \"Humans landed on Mars during the Apollo missions.\"\n","print(\"Answer 1 faithful?\", is_faithful(answer_true, context_text))\n","print(\"Answer 2 faithful?\", is_faithful(answer_false, context_text))\n"]},{"cell_type":"markdown","id":"7c98cf20","metadata":{"id":"7c98cf20"},"source":["#### Exercises (Faithfulness)\n","\n","1. **Expand the stop word list.** Add more common words to `STOP_WORDS` to reduce false positives. Consider words like \"it\", \"they\", \"have\", etc.\n","2. **Allow synonyms.** Modify `extract_keywords` to replace synonyms (e.g. \"man\" with \"humans\") using a simple mapping. How does this affect faithfulness detection?\n","3. **Compute recall and precision.** Implement functions to compute the recall and precision of answer keywords relative to the context keywords, instead of just a boolean faithful/unfaithful output.\n"]},{"cell_type":"markdown","id":"b099a073","metadata":{"id":"b099a073"},"source":["## 5. Validating Structured Outputs\n","\n","When a language model is asked to call a tool or produce a structured response,\n","we often require the result to match a particular schema. For example, a\n","weather API might expect a dictionary with keys `city` and `temperature`.\n","\n","The function below verifies that a JSON string can be parsed and contains\n","expected keys with correct Python types. This simple check can catch obvious\n","errors before passing data to downstream systems. [15]\n"]},{"cell_type":"code","execution_count":null,"id":"684850a5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1759724604653,"user":{"displayName":"Aryan Mistry","userId":"05905357547208756410"},"user_tz":420},"id":"684850a5","outputId":"62a23a08-f20f-4a8f-81cd-d88f7f71556a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Valid output passes? True\n","Invalid output passes? False\n"]}],"source":["\n","import json\n","\n","def validate_json(output: str, schema: dict) -> bool:\n","    \"\"\"Validate JSON output against a simple schema.\n","\n","    The schema maps keys to expected Python types. Returns True if all keys exist and have the correct type.\n","    \"\"\"\n","    try:\n","        data = json.loads(output)\n","    except json.JSONDecodeError:\n","        return False\n","    for key, typ in schema.items():\n","        if key not in data or not isinstance(data[key], typ):\n","            return False\n","    return True\n","\n","schema = {'city': str, 'temperature': float}\n","valid_output = '{\"city\": \"London\", \"temperature\": 18.5}'\n","invalid_output = '{\"temperature\": \"warm\"}'\n","print(\"Valid output passes?\", validate_json(valid_output, schema))\n","print(\"Invalid output passes?\", validate_json(invalid_output, schema))\n"]},{"cell_type":"markdown","id":"4fa6f208","metadata":{"id":"4fa6f208"},"source":["## 6. Simple Guardrails\n","\n","In safety-critical applications you may wish to block or flag outputs that\n","contain sensitive or disallowed content. Here we'll implement a rudimentary\n","check that looks for forbidden keywords in a piece of text. In reality, more\n","sophisticated approaches use classifiers or pattern matching to detect\n","personally identifiable information (PII), toxicity or hallucinations. [15]\n"]},{"cell_type":"code","execution_count":null,"id":"9ba3c845","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1759724604656,"user":{"displayName":"Aryan Mistry","userId":"05905357547208756410"},"user_tz":420},"id":"9ba3c845","outputId":"4e160527-672b-43c7-9488-ca6dd9d4cdfa"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","False\n"]}],"source":["\n","def contains_forbidden_content(text: str, forbidden_keywords: set) -> bool:\n","    \"\"\"Check for forbidden keywords in text.\n","\n","    Useful for building simple guardrails to flag sensitive topics.\n","    \"\"\"\n","    lower = text.lower()\n","    return any(keyword.lower() in lower for keyword in forbidden_keywords)\n","\n","forbidden = {\"social security number\", \"credit card\", \"password\"}\n","print(contains_forbidden_content(\"My password is 12345\", forbidden))\n","print(contains_forbidden_content(\"It's a sunny day\", forbidden))\n"]},{"cell_type":"markdown","id":"3296e82e","metadata":{"id":"3296e82e"},"source":["#### Exercises (Guardrails)\n","\n","1. **Extend forbidden lists.** Create different sets of forbidden words for different contexts (e.g. medical information, financial data). Test your function on a variety of outputs.\n","2. **Case sensitivity.** Modify `contains_forbidden_content` to report not just True/False but which keyword(s) were found and at what positions.\n","3. **Combine checks.** Compose the BLEU, faithfulness and guardrail functions into a single `review_answer` function that rejects answers with low BLEU, unfaithful content or forbidden keywords.\n"]},{"cell_type":"markdown","source":["Foundational LLMs & Transformers\n","1. Vaswani, A., et al. (2017). Attention is All You Need. Advances in Neural Information Processing Systems (NIPS 2017).\n","2. Brown, T. B., et al. (2020). Language Models are Few-Shot Learners. NeurIPS 2020.\n","3. Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. NAACL-HLT 2019.\n","4. OpenAI (2023). GPT-4 Technical Report. arXiv:2303.08774.\n","5. Touvron, H., et al. (2023). LLaMA 2: Open Foundation and Fine-Tuned Chat Models. Meta AI.\n","\n","Generative AI & Sampling\n","6. Goodfellow, I., et al. (2014). Generative Adversarial Nets. NeurIPS 2014.\n","7. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n","8. Neal, R. M. (1993). Probabilistic Inference Using Markov Chain Monte Carlo Methods. Technical Report CRG-TR-93-1, University of Toronto.\n","\n","Retrieval-Augmented Generation (RAG) & Knowledge Grounding\n","9. Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP. NeurIPS 2020.\n","10. deepset ai (2023). Haystack: Open-Source Framework for Search and RAG Applications. https://haystack.deepset.ai\n","11. LangChain (2023). LangChain Documentation and Cookbook. https://python.langchain.com\n","\n","Evaluation & Safety\n","12. Papineni, K., et al. (2002). BLEU: A Method for Automatic Evaluation of Machine Translation. ACL 2002.\n","13. Lin, C.-Y. (2004). ROUGE: A Package for Automatic Evaluation of Summaries. ACL Workshop 2004.\n","14. OpenAI (2024). Evaluating Model Outputs: Faithfulness and Grounding. OpenAI Docs.\n","15. Guardrails AI (2024). Open-Source Guardrails Framework. https://github.com/shreyar/guardrails\n","\n","Prompt Engineering & Instruction Tuning\n","16. White, J. (2023). The Prompting Guide. https://www.promptingguide.ai\n","17. Ouyang, L., et al. (2022). Training Language Models to Follow Instructions with Human Feedback. NeurIPS 2022.\n","\n","Agents & Tool Use\n","18. Yao, S., et al. (2022). ReAct: Synergizing Reasoning and Acting in Language Models. arXiv:2210.03629.\n","19. LangChain (2024). LangChain Agents and Tools Documentation.\n","20. Microsoft (2023). Semantic Kernel Developer Guide. https://learn.microsoft.com/en-us/semantic-kernel/\n","21. Google DeepMind (2024). Gemini Technical Report. arXiv:2312.11805.\n","\n","State, Memory & Orchestration\n","22. LangGraph (2024). Stateful Agent Orchestration Framework. https://langchain-langgraph.vercel.app\n","23. Park, J. S., et al. (2023). Generative Agents: Interactive Simulacra of Human Behavior. arXiv:2304.03442.\n","\n","Pedagogical and Course Design References\n","24. fast.ai (2023). fast.ai Deep Learning Course Notebooks. https://course.fast.ai\n","25. Ng, A. (2023). DeepLearning.AI Short Courses on Generative AI.\n","26. MIT 6.S191, Stanford CS324, UC Berkeley CS294-158. (2022–2024). Course Materials and Public Notebooks for ML and LLMs."],"metadata":{"id":"lZeZBdGPgP2_"},"id":"lZeZBdGPgP2_"},{"cell_type":"code","source":[],"metadata":{"id":"RItGa_EpgQZO"},"id":"RItGa_EpgQZO","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}