{"cells":[{"cell_type":"markdown","id":"vcoVS25Kf1sC","metadata":{"id":"vcoVS25Kf1sC"},"source":["Authored by: Aryan Mistry"]},{"cell_type":"markdown","id":"936a143b","metadata":{"id":"936a143b"},"source":["# Prompt Engineering 101\n","\n","Prompt engineering is the art and science of crafting instructions that guide a language model toward desirable outputs. Because models rely solely on the text you provide to decide what to do, the prompt becomes your **program** for the model. A well‑crafted prompt specifies the task clearly, provides any relevant context, may include examples, and defines how the output should be structured.\n","\n","Throughout this notebook you'll learn core techniques for designing prompts effectively and experiment with them through simple code examples. [16]"]},{"cell_type":"markdown","id":"ae1f5aaa","metadata":{"id":"ae1f5aaa"},"source":["## System vs. User Prompts\n","\n","Large language models often distinguish between a *system* message—describing the assistant’s role or behaviour—and a *user* message containing the actual request. The system prompt sets global behaviour (e.g. \"You are a helpful assistant who translates English to French\"), while the user prompt contains the specific query.\n","\n","When composing prompts:\n","\n","- **Be clear about the role:** tell the model who it should be (e.g., tutor, proofreader).\n","- **Specify the task:** summarise, translate, answer, brainstorm, etc.\n","- **Provide constraints:** tone, output format, style guidelines.\n","- **Include examples when needed:** few‑shot prompts can steer the model toward desired behaviour. [16]"]},{"cell_type":"code","execution_count":1,"id":"26f9e349","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1760046916884,"user":{"displayName":"Harish Kashyap","userId":"08916102011241601104"},"user_tz":420},"id":"26f9e349","outputId":"af57fe3c-c082-41e9-fbcc-940d8595aeaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["bonjour monde\n","I would be pleased to assist you with: Provide the schedule for tomorrow.\n","Echo: Tell me a joke.\n"]}],"source":["def simple_chat(system_prompt: str, user_prompt: str) -> str:\n","    \"\"\"A toy chat function that changes its behaviour based on the system prompt.\n","    This is only illustrative and does not call a real language model.\n","    \"\"\"\n","    system_prompt = system_prompt.lower()\n","    user_prompt = user_prompt.strip()\n","\n","    if 'translate' in system_prompt and 'english to french' in system_prompt:\n","        # naive word-by-word translation dictionary\n","        dictionary = {'hello': 'bonjour', 'world': 'monde', 'friend': 'ami'}\n","        words = user_prompt.lower().split()\n","        return ' '.join(dictionary.get(w, w) for w in words)\n","    elif 'polite' in system_prompt:\n","        return f\"I would be pleased to assist you with: {user_prompt}\"\n","    else:\n","        return f\"Echo: {user_prompt}\"\n","\n","# Examples\n","resp1 = simple_chat('You are a helpful assistant that translates English to French.', 'Hello world')\n","resp2 = simple_chat('You are a polite assistant.', 'Provide the schedule for tomorrow.')\n","resp3 = simple_chat('You are an assistant.', 'Tell me a joke.')\n","print(resp1)\n","print(resp2)\n","print(resp3)"]},{"cell_type":"markdown","id":"f6a63e63","metadata":{"id":"f6a63e63"},"source":["In the toy `simple_chat` function above the behaviour changes depending on the system prompt. When instructed to translate English to French it looks up individual words. When told to be polite it wraps the user request in a courteous response. Otherwise it simply echoes the request. Although rudimentary, this illustrates how a system message influences the output of a language model."]},{"cell_type":"markdown","id":"82b5c7a9","metadata":{"id":"82b5c7a9"},"source":["## Few‑Shot Prompting\n","\n","Few‑shot prompts provide the model with one or more examples of the desired input–output behaviour. The model infers the pattern and applies it to new inputs. Below we implement a simple few‑shot translator that learns mappings from examples provided in the prompt. The function parses the examples and applies them as a lookup; a real model would generalise beyond exact matches. [16]"]},{"cell_type":"code","execution_count":2,"id":"c2ab493b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1760046916901,"user":{"displayName":"Harish Kashyap","userId":"08916102011241601104"},"user_tz":420},"id":"c2ab493b","outputId":"3cb1bd87-9923-4fd3-e2c6-d429e8e6e457"},"outputs":[{"output_type":"stream","name":"stdout","text":["hola amigo\n","goodbye mundo\n"]}],"source":["def few_shot_translate(examples: list[tuple[str, str]], new_sentence: str) -> str:\n","    \"\"\"\n","    A naive few-shot translator that uses provided examples to map words.\n","    Examples should be a list of (source, target) tuples.\n","    \"\"\"\n","    mapping = {src.lower(): tgt for src, tgt in examples}\n","    words = new_sentence.lower().split()\n","    return ' '.join(mapping.get(w, w) for w in words)\n","\n","# Provide a few examples\n","examples = [('hello', 'hola'), ('friend', 'amigo'), ('world', 'mundo')]\n","print(few_shot_translate(examples, 'hello friend'))\n","print(few_shot_translate(examples, 'goodbye world'))"]},{"cell_type":"markdown","id":"574f9bb8","metadata":{"id":"574f9bb8"},"source":["This few‑shot translator simply looks up each word in the provided examples. It does not infer grammar or unseen vocabulary. Real language models use the examples to condition their hidden representations and can generalise to new phrases."]},{"cell_type":"markdown","id":"2dbba31a","metadata":{"id":"2dbba31a"},"source":["## Guidelines for Effective Prompting\n","\n","When designing prompts it helps to think like a teacher: set expectations, provide examples and define the desired output. Some general principles include:\n","\n","1. **Start simple and iterate:** Begin with a straightforward instruction. Try the prompt, examine the output, and iteratively refine your instructions. Avoid writing a complicated prompt all at once.\n","2. **Be explicit about the task:** State clearly what you want the model to do (e.g. \"Translate the following sentence into French\", \"Summarize this paragraph in one sentence\", \"Classify the sentiment as positive, negative or neutral\").\n","3. **Provide relevant context:** Supply background information or constraints so the model does not have to guess, such as assumptions about the audience or domain-specific knowledge.\n","4. **Specify the output format:** If you need a numbered list, a JSON object, bullet points or a particular tone, say so explicitly.\n","5. **Use examples when appropriate:** Few‑shot examples (input–output pairs) illustrate the pattern you expect and can improve performance on classification, translation and transformation tasks.\n","6. **Give positive instructions:** Phrase your request in terms of what the model should do rather than what it should avoid. For example, \"Recommend five movies suitable for a family audience\" rather than \"Don't recommend any movies that are not family friendly\".\n","7. **Avoid ambiguity and cleverness:** Use simple, direct language rather than puns or sarcasm. If a prompt could be misinterpreted, add clarifying details.\n","\n","The following sections expand on these principles with concrete examples and exercises. [16]"]},{"cell_type":"markdown","id":"f151345c","metadata":{"id":"f151345c"},"source":["## Prompt Elements: Instruction, Context, Examples, Output Format\n","\n","A good prompt often includes four key elements:\n","\n","* **Instruction:** A clear description of what you want the model to do (e.g. \"Summarize the following text in one sentence\").\n","* **Context:** Any background information or constraints the model needs to perform the task (e.g. \"Assume the reader has a basic knowledge of physics\").\n","* **Examples:** One or more input→output pairs that illustrate the desired behaviour. This is called *few‑shot prompting*.\n","* **Output format:** Explicit directions on how to structure the response (e.g. \"Return the answer as a JSON object with keys `name` and `category`\", or \"Provide the summary in bullet points\").\n","\n","By composing these elements, you can dramatically improve the quality of the model’s response. The next sections show how to apply these ideas in practice. [16]"]},{"cell_type":"markdown","id":"f63d3025","metadata":{"id":"f63d3025"},"source":["## Zero‑Shot and Few‑Shot Prompting\n","\n","**Zero‑shot prompting** means asking the model to perform a task without providing any examples. You rely entirely on the instruction and context. This works surprisingly well for many tasks, but the model may misinterpret your intent if you aren't specific.\n","\n","**Few‑shot prompting** embeds a few input→output examples directly in the prompt. The model sees the pattern and generalises it to new inputs. This technique can boost performance on tasks like translation, classification or extraction. When writing few‑shot prompts, make sure your examples are representative of the task and your labels are consistent. [16]"]},{"cell_type":"code","execution_count":3,"id":"9563d797","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1760046916932,"user":{"displayName":"Harish Kashyap","userId":"08916102011241601104"},"user_tz":420},"id":"9563d797","outputId":"bcf2bc46-aa54-42da-fd9d-bf7870f82797"},"outputs":[{"output_type":"stream","name":"stdout","text":["Zero-shot result: positive\n","Few-shot result: positive\n"]}],"source":["def zero_shot_sentiment(sentence: str) -> str:\n","    # A naive zero-shot sentiment classifier that uses keyword heuristics.\n","    positive_words = {'love', 'delicious', 'good', 'happy', 'excellent'}\n","    negative_words = {'hate', 'bad', 'terrible', 'awful', 'horrible'}\n","    words = set(sentence.lower().split())\n","    if words & positive_words and not (words & negative_words):\n","        return 'positive'\n","    elif words & negative_words and not (words & positive_words):\n","        return 'negative'\n","    else:\n","        return 'neutral'\n","\n","\n","def few_shot_sentiment(examples: list[tuple[str, str]], new_sentence: str) -> str:\n","    # A naive few-shot classifier: uses examples to build a lookup table.\n","    label_vocab = {}\n","    for sent, label in examples:\n","        for word in sent.lower().split():\n","            label_vocab[word] = label\n","    votes = {'positive': 0, 'negative': 0, 'neutral': 0}\n","    for word in new_sentence.lower().split():\n","        if word in label_vocab:\n","            votes[label_vocab[word]] += 1\n","    return max(votes, key=votes.get)\n","\n","\n","# Compare zero-shot vs few-shot on an example sentence\n","sentence = \"The food was delicious and the service excellent\"\n","print('Zero-shot result:', zero_shot_sentiment(sentence))\n","print('Few-shot result:', few_shot_sentiment([\n","    (\"I love this product\", \"positive\"),\n","    (\"This is terrible\", \"negative\")\n","], sentence))"]},{"cell_type":"markdown","id":"28fc2c38","metadata":{"id":"28fc2c38"},"source":["## Examples: Translation, Summarization, and Classification\n","\n","Below are some example prompts that illustrate how clarity and specificity affect model outputs.\n","\n","* **Translation:**\n","\n","  \"Translate the following sentence into French:\n","\n","    'The meeting will take place tomorrow afternoon.'\"\n","\n","  By stating the task (\"Translate\") and specifying the target language, you reduce ambiguity.\n","\n","* **Summarization:**\n","\n","  \"In one or two sentences, summarize the main points of the paragraph below, focusing on the major events:\n","\n","    [insert paragraph here]\"\n","\n","  This prompt instructs the model to produce a concise summary and clarifies what to focus on.\n","\n","* **Classification:**\n","\n","  \"Classify the sentiment of the sentence below as 'positive', 'negative', or 'neutral':\n","\n","    'I waited 45 minutes for my food and it was cold when it arrived.'\n","\n","Answer with just the label.\"\n","\n","  The prompt states the task, the possible labels, the input, and the desired output format.\n","\n","* **Structured Output:**\n","\n","  \"Extract the chemical names from the paragraph below and return them as a JSON array under the key `chemicals`:\n","\n","    [insert paragraph here]\"\n","\n","  Here you combine instruction, context, and explicit output formatting to guide the model. [16]"]},{"cell_type":"markdown","id":"1aefc7ef","metadata":{"id":"1aefc7ef"},"source":["## Putting It into Practice\n","\n","The toy functions defined above (`simple_chat` and `few_shot_translate`) can be used to experiment with prompt structure. For example, you can change the system prompt to instruct the model to reply with exaggerated enthusiasm or to answer only in the style of a pirate. Because these functions are extremely simple, they provide immediate feedback about how prompt changes affect behaviour.\n","\n","In a real LLM setting you would replace these toy functions with calls to an API or library such as `openai.ChatCompletion` or Hugging Face’s `pipeline`. The same principles still apply."]},{"cell_type":"code","execution_count":4,"id":"89aa3d7b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1760046916932,"user":{"displayName":"Harish Kashyap","userId":"08916102011241601104"},"user_tz":420},"id":"89aa3d7b","outputId":"d4602ddb-1956-4efc-fd73-622ca0bedd7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Default behaviour: Echo: What is the capital of France?\n","Polite persona: I would be pleased to assist you with: What is the capital of France?\n","Few-shot translation: hola mundo\n"]}],"source":["# Experiment with system and user prompts.\n","# Try changing the system prompt to different personas and see how the reply changes.\n","print('Default behaviour:', simple_chat('you are a neutral assistant', 'What is the capital of France?'))\n","print('Polite persona:', simple_chat('You are a very polite assistant.', 'What is the capital of France?'))\n","\n","# Now build a few-shot translation example\n","examples = [('hello', 'hola'), ('world', 'mundo'), ('cat', 'gato'), ('dog', 'perro')]\n","print('Few-shot translation:', few_shot_translate(examples, 'hello world'))\n","\n","# TODO: Extend this example by adding more examples or changing the target language."]},{"cell_type":"markdown","id":"b567c8ec","metadata":{"id":"b567c8ec"},"source":["## Exercises\n","\n","1. **Rewrite a prompt for clarity:** The prompt *\"Translate this into another language.\"* is vague. Rewrite it to be specific about which language and how the translation should be formatted.\n","2. **Design a zero-shot classification prompt:** Write a prompt that asks a model to classify whether a news article is about sports, politics, technology, or entertainment. Make sure to include instructions and a clear output format.\n","3. **Create a few-shot prompt:** Using the `few_shot_sentiment` function as a stand-in for a model, design a prompt with two or three examples that help classify the sentiment of a new sentence. Experiment by adding more examples and observing how the classification changes.\n","4. **Specify an output format:** Write a prompt that instructs the model to extract the names of all countries mentioned in a paragraph and return them as a JSON list.\n","5. **Positive vs negative instructions:** Write a prompt that tells a model to recommend five books in the science fiction genre and politely decline to discuss personal information. Use positive phrasing to instruct the model what to do.\n","6. **Iterate and refine:** Start with a basic prompt asking a model to summarise an article. Then iteratively refine your prompt to specify length, target audience, and desired tone. Reflect on how each change could influence the response."]},{"cell_type":"markdown","source":["Foundational LLMs & Transformers\n","1. Vaswani, A., et al. (2017). Attention is All You Need. Advances in Neural Information Processing Systems (NIPS 2017).\n","2. Brown, T. B., et al. (2020). Language Models are Few-Shot Learners. NeurIPS 2020.\n","3. Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. NAACL-HLT 2019.\n","4. OpenAI (2023). GPT-4 Technical Report. arXiv:2303.08774.\n","\n","5. Touvron, H., et al. (2023). LLaMA 2: Open Foundation and Fine-Tuned Chat Models. Meta AI.\n","\n","\n","Generative AI & Sampling\n","\n","6. Goodfellow, I., et al. (2014). Generative Adversarial Nets. NeurIPS 2014.\n","7. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n","8. Neal, R. M. (1993). Probabilistic Inference Using Markov Chain Monte Carlo Methods. Technical Report CRG-TR-93-1, University of Toronto.\n","\n","Retrieval-Augmented Generation (RAG) & Knowledge Grounding\n","\n","9. Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP. NeurIPS 2020.\n","10. deepset ai (2023). Haystack: Open-Source Framework for Search and RAG Applications. https://haystack.deepset.ai\n","11. LangChain (2023). LangChain Documentation and Cookbook. https://python.langchain.com\n","\n","Evaluation & Safety\n","\n","12. Papineni, K., et al. (2002). BLEU: A Method for Automatic Evaluation of Machine Translation. ACL 2002.\n","13. Lin, C.-Y. (2004). ROUGE: A Package for Automatic Evaluation of Summaries. ACL Workshop 2004.\n","14. OpenAI (2024). Evaluating Model Outputs: Faithfulness and Grounding. OpenAI Docs.\n","15. Guardrails AI (2024). Open-Source Guardrails Framework. https://github.com/shreyar/guardrails\n","\n","Prompt Engineering & Instruction Tuning\n","\n","16. White, J. (2023). The Prompting Guide. https://www.promptingguide.ai\n","17. Ouyang, L., et al. (2022). Training Language Models to Follow Instructions with Human Feedback. NeurIPS 2022.\n","\n","Agents & Tool Use\n","\n","18. Yao, S., et al. (2022). ReAct: Synergizing Reasoning and Acting in Language Models. arXiv:2210.03629.\n","19. LangChain (2024). LangChain Agents and Tools Documentation.\n","20. Microsoft (2023). Semantic Kernel Developer Guide. https://learn.microsoft.com/en-us/semantic-kernel/\n","21. Google DeepMind (2024). Gemini Technical Report. arXiv:2312.11805.\n","\n","State, Memory & Orchestration\n","\n","22. LangGraph (2024). Stateful Agent Orchestration Framework. https://langchain-langgraph.vercel.app\n","23. Park, J. S., et al. (2023). Generative Agents: Interactive Simulacra of Human Behavior. arXiv:2304.03442.\n","\n","Pedagogical and Course Design References\n","\n","24. fast.ai (2023). fast.ai Deep Learning Course Notebooks. https://course.fast.ai\n","25. Ng, A. (2023). DeepLearning.AI Short Courses on Generative AI.\n","26. MIT 6.S191, Stanford CS324, UC Berkeley CS294-158. (2022–2024). Course Materials and Public Notebooks for ML and LLMs."],"metadata":{"id":"slMqaE-jgLwu"},"id":"slMqaE-jgLwu"},{"cell_type":"code","source":[],"metadata":{"id":"IEWsuRb-gMPk","executionInfo":{"status":"ok","timestamp":1760046916932,"user_tz":420,"elapsed":1,"user":{"displayName":"Harish Kashyap","userId":"08916102011241601104"}}},"id":"IEWsuRb-gMPk","execution_count":4,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}